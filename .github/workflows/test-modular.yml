name: Modular Test Suite

on:
  push:
    branches: [ "main", "develop", "AI-Enhancements" ]
    paths:
      - 'tests/**'
      - '*.py'
      - 'requirements.txt'
  pull_request:
    branches: [ "main" ]
    paths:
      - 'tests/**'
      - '*.py'
      - 'requirements.txt'

jobs:
  test-modules:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        test-group: 
          - "core"
          - "ai"
          - "generators" 
          - "tools"
          - "utils"
          - "integration"

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11

    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-cov pytest-xdist

    - name: Run Core Tests
      if: matrix.test-group == 'core'
      run: |
        python -m pytest tests/test_server_core.py -v --cov=kotlin_mcp_server --cov-report=xml --cov-report=term-missing
        echo "COVERAGE_FILE=.coverage.core" >> $GITHUB_ENV

    - name: Run AI Tests
      if: matrix.test-group == 'ai'
      run: |
        python -m pytest tests/ai/ -v --cov=ai --cov-report=xml --cov-report=term-missing
        echo "COVERAGE_FILE=.coverage.ai" >> $GITHUB_ENV

    - name: Run Generator Tests
      if: matrix.test-group == 'generators'
      run: |
        python -m pytest tests/generators/ -v --cov=generators --cov-report=xml --cov-report=term-missing
        echo "COVERAGE_FILE=.coverage.generators" >> $GITHUB_ENV

    - name: Run Tools Tests
      if: matrix.test-group == 'tools'
      run: |
        python -m pytest tests/tools/ -v --cov=tools --cov-report=xml --cov-report=term-missing
        echo "COVERAGE_FILE=.coverage.tools" >> $GITHUB_ENV

    - name: Run Utils Tests
      if: matrix.test-group == 'utils'
      run: |
        python -m pytest tests/utils/ -v --cov=utils --cov-report=xml --cov-report=term-missing
        echo "COVERAGE_FILE=.coverage.utils" >> $GITHUB_ENV

    - name: Run Integration Tests
      if: matrix.test-group == 'integration'
      run: |
        python -m pytest tests/test_api_tools.py tests/test_ui_layout_tools.py -v --cov=. --cov-report=xml --cov-report=term-missing
        echo "COVERAGE_FILE=.coverage.integration" >> $GITHUB_ENV

    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: ${{ matrix.test-group }}
        name: coverage-${{ matrix.test-group }}
        fail_ci_if_error: false

    - name: Upload test artifacts
      uses: actions/upload-artifact@v4
      if: failure()
      with:
        name: test-results-${{ matrix.test-group }}
        path: |
          .coverage*
          coverage.xml
          pytest.log
        retention-days: 7

  test-summary:
    runs-on: ubuntu-latest
    needs: test-modules
    if: always()

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-cov

    - name: Run Full Test Suite
      run: |
        python -m pytest tests/ -v --cov=. --cov-report=html --cov-report=xml --cov-report=term-missing --tb=short

    - name: Generate Test Summary
      run: |
        echo "## Test Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Coverage Report" >> $GITHUB_STEP_SUMMARY
        python -c "
        import xml.etree.ElementTree as ET
        try:
            tree = ET.parse('coverage.xml')
            root = tree.getroot()
            coverage = root.attrib.get('line-rate', '0')
            coverage_pct = float(coverage) * 100
            print(f'Overall Coverage: {coverage_pct:.2f}%')
            with open('coverage_summary.txt', 'w') as f:
                f.write(f'Coverage: {coverage_pct:.2f}%\\n')
        except Exception as e:
            print(f'Could not parse coverage: {e}')
            with open('coverage_summary.txt', 'w') as f:
                f.write('Coverage: N/A\\n')
        "
        
        if [ -f coverage_summary.txt ]; then
          cat coverage_summary.txt >> $GITHUB_STEP_SUMMARY
        fi

    - name: Upload comprehensive coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: comprehensive
        name: coverage-full-suite
        fail_ci_if_error: false

    - name: Upload HTML coverage report
      uses: actions/upload-artifact@v4
      with:
        name: coverage-html-report
        path: htmlcov/
        retention-days: 14

  performance-test:
    runs-on: ubuntu-latest
    needs: test-modules

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-benchmark

    - name: Run Performance Tests
      run: |
        python -c "
        import asyncio
        import time
        import tempfile
        import statistics
        from kotlin_mcp_server import KotlinMCPServer
        
        async def benchmark_server():
            print('ðŸš€ Running performance benchmarks...')
            
            # Test server initialization
            init_times = []
            for i in range(5):
                start = time.time()
                server = KotlinMCPServer(f'perf-test-{i}')
                server.set_project_path(tempfile.mkdtemp())
                init_times.append(time.time() - start)
            
            avg_init = statistics.mean(init_times)
            print(f'âœ… Server initialization: {avg_init:.3f}s (avg)')
            
            # Test tool listing
            server = KotlinMCPServer('perf-test')
            server.set_project_path(tempfile.mkdtemp())
            
            list_times = []
            for i in range(10):
                start = time.time()
                tools = await server.handle_list_tools()
                list_times.append(time.time() - start)
            
            avg_list = statistics.mean(list_times)
            tool_count = len(tools.get('tools', []))
            print(f'âœ… Tool listing ({tool_count} tools): {avg_list:.3f}s (avg)')
            
            # Test tool execution
            exec_times = []
            for i in range(5):
                start = time.time()
                result = await server.handle_call_tool('create_kotlin_class', {
                    'class_name': f'PerfTest{i}',
                    'package_name': 'com.perf.test'
                })
                exec_times.append(time.time() - start)
            
            avg_exec = statistics.mean(exec_times)
            print(f'âœ… Tool execution: {avg_exec:.3f}s (avg)')
            
            # Performance assertions
            assert avg_init < 1.0, f'Server init too slow: {avg_init:.3f}s'
            assert avg_list < 2.0, f'Tool listing too slow: {avg_list:.3f}s'
            assert avg_exec < 3.0, f'Tool execution too slow: {avg_exec:.3f}s'
            
            print('ðŸŽ¯ All performance benchmarks passed!')
        
        asyncio.run(benchmark_server())
        "

    - name: Performance Summary
      run: |
        echo "## Performance Test Results" >> $GITHUB_STEP_SUMMARY
        echo "âœ… All performance benchmarks completed successfully" >> $GITHUB_STEP_SUMMARY
        echo "- Server initialization: < 1.0s" >> $GITHUB_STEP_SUMMARY
        echo "- Tool listing: < 2.0s" >> $GITHUB_STEP_SUMMARY
        echo "- Tool execution: < 3.0s" >> $GITHUB_STEP_SUMMARY
